{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db18d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./params.json\", mode = \"r\", encoding = \"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    model_path = data[\"model_path\"]\n",
    "    dataset_path_train = data[\"dataset_path\"][\"train\"]\n",
    "    dataset_path_test = data[\"dataset_path\"][\"test\"]\n",
    "    num_single_sample_timesteps = data[\"num_single_sample_timesteps\"]\n",
    "    input_window_length = data[\"input_window_length\"]\n",
    "    label_window_length = data[\"label_window_length\"]\n",
    "    input_features = data[\"input_features\"]\n",
    "    label_features = data[\"label_features\"]\n",
    "\n",
    "    # Usually window_stride = 1 since we want to check each input window\n",
    "    window_stride = 20\n",
    "    seed_val = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0717e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(seed_val)\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa0c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.pipeline.Model import TimeSeriesHuggingFaceTransformer\n",
    "from utils.pipeline.Data import get_mean_std_respected_temporal, WindowedIterableDataset\n",
    "from utils.pipeline.Run import autoregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36f9adb-5563-4603-aeb9-7b6357e7622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats = get_mean_std_respected_temporal(\n",
    "#     dataset_path = dataset_path_train,\n",
    "#     cols = input_features\n",
    "# )\n",
    "\n",
    "stats = get_mean_std_respected_temporal(\n",
    "    dataset_path = dataset_path_train,\n",
    "    cols = input_features,\n",
    "    num_single_sample_timesteps = num_single_sample_timesteps,\n",
    "    input_window_len = input_window_length,\n",
    "    label_window_len = label_window_length,\n",
    "    window_stride = window_stride\n",
    ")\n",
    "\n",
    "df_test = WindowedIterableDataset(\n",
    "    dataset_path = dataset_path_test,\n",
    "    stats = stats,\n",
    "    input_features = input_features,\n",
    "    label_features = label_features,\n",
    "    num_single_sample_timesteps = num_single_sample_timesteps,\n",
    "    stride = window_stride,\n",
    "    input_window_length = input_window_length,\n",
    "    label_window_length = label_window_length,\n",
    "    inference = True\n",
    ")\n",
    "\n",
    "data_loader_test = DataLoader(\n",
    "    df_test,\n",
    "    batch_size = 1,    # One windowed datapoint at a time\n",
    "    pin_memory = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d89bed4",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_path, weights_only = False).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0.0\n",
    "test_progress_bar = tqdm(\n",
    "    data_loader_test\n",
    ")\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "target_timeseries_idx = 0\n",
    "feature = \"u_list\"\n",
    "figure_range = 1\n",
    "\n",
    "num_datapoints_per_timeseries = 1 + (num_single_sample_timesteps - (input_window_length + label_window_length) + 1) // window_stride\n",
    "\n",
    "with torch.no_grad():\n",
    "    for datapoint_idx, (batch_x, batch_y, x_labels) in enumerate(test_progress_bar):\n",
    "        if(datapoint_idx >= target_timeseries_idx * num_datapoints_per_timeseries and datapoint_idx < (target_timeseries_idx + 1) * num_datapoints_per_timeseries):\n",
    "            window_idx = datapoint_idx % num_datapoints_per_timeseries\n",
    "\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            preds = autoregress(\n",
    "                model = model,\n",
    "                batch_x = batch_x,\n",
    "                batch_y = batch_y,\n",
    "                device = device,\n",
    "                extract_attention = True\n",
    "            )\n",
    "            \n",
    "            loss = criterion(preds, batch_y)\n",
    "            test_progress_bar.set_postfix({\n",
    "                \"single_test_loss\": f\"{loss.item():.6f}\"\n",
    "            })\n",
    "\n",
    "            x = list(range(num_single_sample_timesteps))\n",
    "\n",
    "            feature_idx = label_features.index(feature)\n",
    "\n",
    "            feature_label = batch_y[0, :, feature_idx].cpu()\n",
    "            feature_pred = preds[0, :, feature_idx].cpu()\n",
    "            feature_x_labels = x_labels[0, :, feature_idx]\n",
    "\n",
    "            # feature_pred = (feature_pred * stats[\"std\"][feature]) + stats[\"mean\"][feature]\n",
    "            # feature_label = (feature_label * stats[\"std\"][feature]) + stats[\"mean\"][feature]\n",
    "            # feature_x_labels = (feature_x_labels * stats[\"std\"][feature]) + stats[\"mean\"][feature]\n",
    "        \n",
    "            feature_pred = (feature_pred * stats[window_idx, f\"{feature}_std\"]) + stats[window_idx, f\"{feature}_mean\"]\n",
    "            feature_label = (feature_label * stats[window_idx, f\"{feature}_std\"]) + stats[window_idx, f\"{feature}_mean\"]\n",
    "            # No normalization on x_labels in WindowedIterableDataset!\n",
    "\n",
    "            sns.set_theme(style = \"whitegrid\")\n",
    "            fig, ax = plt.subplots(figsize = (16, 8))\n",
    "            ax.set_ylim(-figure_range, figure_range)\n",
    "\n",
    "            ax.axvspan(\n",
    "                x[window_idx * window_stride],\n",
    "                x[window_idx * window_stride + input_window_length - 1],\n",
    "                color = \"green\",\n",
    "                alpha = 0.3,\n",
    "                label = \"Input Sequence Region\"\n",
    "            )\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x = x,\n",
    "                y = feature_x_labels,\n",
    "                marker = \"o\",\n",
    "                label = f\"{feature}_label (circles)\",\n",
    "                color = \"blue\",\n",
    "                ax = ax\n",
    "            )\n",
    "\n",
    "            sns.scatterplot(\n",
    "                x = x[(input_window_length + window_idx * window_stride):(input_window_length + window_idx * window_stride + label_window_length)],\n",
    "                y = feature_pred,\n",
    "                marker = \"x\",\n",
    "                label = f\"{feature}_pred (crosses)\",\n",
    "                color = \"red\",\n",
    "                ax = ax\n",
    "            )\n",
    "\n",
    "            ax.set_title(f\"{feature} Value Ground-Truth vs. Prediction\")\n",
    "            ax.set_xlabel(\"Timesteps\")\n",
    "            ax.set_ylabel(feature)\n",
    "            ax.legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            avg_attn_vals = model.get_average_attention_values()\n",
    "\n",
    "            for i in range(20):                                      # First 20 predictions following input sequence \n",
    "                output_row = avg_attn_vals[i, :]\n",
    "                top_k_indices = np.argsort(output_row)[::-1][:10]    # Top 10 highest attention input timesteps\n",
    "                top_k_scores = output_row[top_k_indices]\n",
    "                print(f\"Output Timestep {input_window_length + window_idx * window_stride + i + 1}\")\n",
    "                print(f\"    Input Timesteps {top_k_indices + (window_idx * window_stride + 1)}\")\n",
    "                print(f\"    Scores {[f'{score:.5f}' for score in top_k_scores]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9039c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a7145f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8bfcde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
