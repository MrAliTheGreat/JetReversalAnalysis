{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "917c5cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./params.json\", mode = \"r\", encoding = \"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    seed_val = data[\"seed_val\"]\n",
    "    model_path = data[\"model_path\"]\n",
    "    dataset_path_train = data[\"dataset_path\"][\"train\"]\n",
    "    dataset_path_val = data[\"dataset_path\"][\"validation\"]\n",
    "    dataset_path_test = data[\"dataset_path\"][\"test\"]\n",
    "    num_single_sample_timesteps = data[\"num_single_sample_timesteps\"]\n",
    "    window_stride = data[\"window_stride\"]\n",
    "    input_window_length = data[\"input_window_length\"]\n",
    "    label_window_length = data[\"label_window_length\"]\n",
    "    input_features = data[\"input_features\"]\n",
    "    label_features = data[\"label_features\"]\n",
    "    relative_attention_num_buckets = data[\"relative_attention_num_buckets\"]\n",
    "    embedding_dim = data[\"embedding_dim\"]\n",
    "    num_attention_head = data[\"num_attention_head\"]\n",
    "    num_encoder_layers = data[\"num_encoder_layers\"]\n",
    "    num_decoder_layers = data[\"num_decoder_layers\"]\n",
    "    position_wise_nn_dim = data[\"position_wise_nn_dim\"]\n",
    "    dropout = data[\"dropout\"]\n",
    "    batch_size = data[\"batch_size\"]\n",
    "    epochs = data[\"epochs\"]\n",
    "    learning_rate = data[\"learning_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b44d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(seed_val)\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c01badd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/labnet5/gr5/abahari/Documents/Thesis/src/thesis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.regression import R2Score\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.pipeline.Data import get_mean_std_respected_temporal, WindowedIterableDataset\n",
    "from utils.pipeline.Model import TimeSeriesHuggingFaceTransformer\n",
    "from utils.pipeline.Run import train, validate\n",
    "from utils.pipeline.Monitor import Overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33375a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TRAIN #####\n",
    "# stats = get_mean_std(\n",
    "#     dataset_path = dataset_path_train,\n",
    "#     cols = input_features\n",
    "# )\n",
    "\n",
    "input_stats = get_mean_std_respected_temporal(\n",
    "    dataset_path = dataset_path_train,\n",
    "    cols = input_features,\n",
    "    num_single_sample_timesteps = num_single_sample_timesteps,\n",
    "    input_window_len = input_window_length,\n",
    "    label_window_len = label_window_length,\n",
    "    window_stride = window_stride\n",
    ")\n",
    "if(set(input_features) == set(label_features)):\n",
    "    output_stats = input_stats\n",
    "else:\n",
    "    output_stats = get_mean_std_respected_temporal(\n",
    "        dataset_path = dataset_path_train,\n",
    "        cols = label_features,\n",
    "        num_single_sample_timesteps = num_single_sample_timesteps,\n",
    "        input_window_len = input_window_length,\n",
    "        label_window_len = label_window_length,\n",
    "        window_stride = window_stride\n",
    "    )\n",
    "\n",
    "df_train = WindowedIterableDataset(\n",
    "    dataset_path = dataset_path_train,\n",
    "    input_stats = input_stats,\n",
    "    label_stats = output_stats,\n",
    "    input_features = input_features,\n",
    "    label_features = label_features,\n",
    "    num_single_sample_timesteps = num_single_sample_timesteps,\n",
    "    stride = window_stride,\n",
    "    input_window_length = input_window_length,\n",
    "    label_window_length = label_window_length\n",
    ")\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "    df_train,\n",
    "    batch_size = batch_size,\n",
    "    # num_workers = 0,\n",
    "    # prefetch_factor = 12,\n",
    "    # persistent_workers = False,\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "##### VALIDATION #####\n",
    "df_val = WindowedIterableDataset(\n",
    "    dataset_path = dataset_path_val,\n",
    "    input_stats = input_stats,\n",
    "    label_stats = output_stats,\n",
    "    input_features = input_features,\n",
    "    label_features = label_features,\n",
    "    num_single_sample_timesteps = num_single_sample_timesteps,\n",
    "    stride = window_stride,\n",
    "    input_window_length = input_window_length,\n",
    "    label_window_length = label_window_length\n",
    ")\n",
    "\n",
    "data_loader_val = DataLoader(\n",
    "    df_val,\n",
    "    batch_size = batch_size,\n",
    "    # num_workers = 0,\n",
    "    # prefetch_factor = 12,\n",
    "    # persistent_workers = False,\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "##### TEST #####\n",
    "df_test = WindowedIterableDataset(\n",
    "    dataset_path = dataset_path_test,\n",
    "    input_stats = input_stats,\n",
    "    label_stats = output_stats,\n",
    "    input_features = input_features,\n",
    "    label_features = label_features,\n",
    "    num_single_sample_timesteps = num_single_sample_timesteps,\n",
    "    stride = window_stride,\n",
    "    input_window_length = input_window_length,\n",
    "    label_window_length = label_window_length\n",
    ")\n",
    "\n",
    "data_loader_test = DataLoader(\n",
    "    df_test,\n",
    "    batch_size = batch_size,\n",
    "    # num_workers = 0,\n",
    "    # prefetch_factor = 12,\n",
    "    # persistent_workers = False,\n",
    "    pin_memory = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cfc6517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters in the model: 1171589\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 758it [00:45, 16.50it/s, train_loss=-0.537813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Train Loss: -0.191257, Train R2: 0.929041\n",
      "\n",
      "Worst 5 Time-Steps Train R2:\n",
      "    Time-step 1: R2 = 0.771168\n",
      "    Time-step 2: R2 = 0.911358\n",
      "    Time-step 3: R2 = 0.922869\n",
      "    Time-step 50: R2 = 0.925059\n",
      "    Time-step 49: R2 = 0.926885\n",
      "Best 5 Time-Steps Train R2:\n",
      "    Time-step 14: R2 = 0.936603\n",
      "    Time-step 11: R2 = 0.936576\n",
      "    Time-step 10: R2 = 0.936552\n",
      "    Time-step 16: R2 = 0.936543\n",
      "    Time-step 13: R2 = 0.936541\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 219it [00:34,  6.34it/s, val_loss=20.009001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Val Loss: 24.158529, Val R2: 0.548052\n",
      "\n",
      "Worst 5 Time-Steps Val R2:\n",
      "    Time-step 50: R2 = 0.145167\n",
      "    Time-step 49: R2 = 0.158402\n",
      "    Time-step 48: R2 = 0.168296\n",
      "    Time-step 47: R2 = 0.179113\n",
      "    Time-step 46: R2 = 0.191940\n",
      "Best 5 Time-Steps Val R2:\n",
      "    Time-step 1: R2 = 0.970884\n",
      "    Time-step 2: R2 = 0.959593\n",
      "    Time-step 3: R2 = 0.946424\n",
      "    Time-step 4: R2 = 0.933629\n",
      "    Time-step 5: R2 = 0.920661\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 758it [00:46, 16.43it/s, train_loss=-0.633574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Train Loss: -0.563941, Train R2: 0.971946\n",
      "\n",
      "Worst 5 Time-Steps Train R2:\n",
      "    Time-step 1: R2 = 0.926785\n",
      "    Time-step 2: R2 = 0.962892\n",
      "    Time-step 3: R2 = 0.968839\n",
      "    Time-step 50: R2 = 0.970784\n",
      "    Time-step 49: R2 = 0.971162\n",
      "Best 5 Time-Steps Train R2:\n",
      "    Time-step 10: R2 = 0.974614\n",
      "    Time-step 11: R2 = 0.974583\n",
      "    Time-step 13: R2 = 0.974509\n",
      "    Time-step 17: R2 = 0.974459\n",
      "    Time-step 9: R2 = 0.974442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 219it [00:34,  6.32it/s, val_loss=24.147175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Val Loss: 28.373122, Val R2: 0.605758\n",
      "\n",
      "Worst 5 Time-Steps Val R2:\n",
      "    Time-step 50: R2 = 0.209721\n",
      "    Time-step 49: R2 = 0.224350\n",
      "    Time-step 48: R2 = 0.236432\n",
      "    Time-step 47: R2 = 0.249503\n",
      "    Time-step 46: R2 = 0.263944\n",
      "Best 5 Time-Steps Val R2:\n",
      "    Time-step 1: R2 = 0.976499\n",
      "    Time-step 2: R2 = 0.965820\n",
      "    Time-step 3: R2 = 0.954632\n",
      "    Time-step 4: R2 = 0.943979\n",
      "    Time-step 5: R2 = 0.933189\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 758it [00:45, 16.52it/s, train_loss=-0.732729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Train Loss: -0.642471, Train R2: 0.974484\n",
      "\n",
      "Worst 5 Time-Steps Train R2:\n",
      "    Time-step 1: R2 = 0.938717\n",
      "    Time-step 2: R2 = 0.966983\n",
      "    Time-step 3: R2 = 0.972133\n",
      "    Time-step 50: R2 = 0.973547\n",
      "    Time-step 49: R2 = 0.973763\n",
      "Best 5 Time-Steps Train R2:\n",
      "    Time-step 10: R2 = 0.976565\n",
      "    Time-step 11: R2 = 0.976562\n",
      "    Time-step 12: R2 = 0.976537\n",
      "    Time-step 13: R2 = 0.976530\n",
      "    Time-step 8: R2 = 0.976505\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 219it [00:34,  6.44it/s, val_loss=24.340273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Val Loss: 35.993988, Val R2: 0.618299\n",
      "\n",
      "Worst 5 Time-Steps Val R2:\n",
      "    Time-step 50: R2 = 0.236048\n",
      "    Time-step 49: R2 = 0.249873\n",
      "    Time-step 48: R2 = 0.261797\n",
      "    Time-step 47: R2 = 0.274604\n",
      "    Time-step 46: R2 = 0.288494\n",
      "Best 5 Time-Steps Val R2:\n",
      "    Time-step 1: R2 = 0.980266\n",
      "    Time-step 2: R2 = 0.969724\n",
      "    Time-step 3: R2 = 0.959285\n",
      "    Time-step 4: R2 = 0.949201\n",
      "    Time-step 5: R2 = 0.938734\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 758it [00:45, 16.52it/s, train_loss=-0.754862]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Train Loss: -0.682100, Train R2: 0.975702\n",
      "\n",
      "Worst 5 Time-Steps Train R2:\n",
      "    Time-step 1: R2 = 0.944690\n",
      "    Time-step 2: R2 = 0.969180\n",
      "    Time-step 3: R2 = 0.973633\n",
      "    Time-step 50: R2 = 0.974931\n",
      "    Time-step 49: R2 = 0.975028\n",
      "Best 5 Time-Steps Train R2:\n",
      "    Time-step 10: R2 = 0.977539\n",
      "    Time-step 13: R2 = 0.977535\n",
      "    Time-step 9: R2 = 0.977486\n",
      "    Time-step 12: R2 = 0.977480\n",
      "    Time-step 14: R2 = 0.977454\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 219it [00:34,  6.43it/s, val_loss=29.293171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Val Loss: 34.325264, Val R2: 0.632112\n",
      "\n",
      "Worst 5 Time-Steps Val R2:\n",
      "    Time-step 50: R2 = 0.265137\n",
      "    Time-step 49: R2 = 0.278811\n",
      "    Time-step 48: R2 = 0.290247\n",
      "    Time-step 47: R2 = 0.302938\n",
      "    Time-step 46: R2 = 0.316487\n",
      "Best 5 Time-Steps Val R2:\n",
      "    Time-step 1: R2 = 0.982434\n",
      "    Time-step 2: R2 = 0.972560\n",
      "    Time-step 3: R2 = 0.962665\n",
      "    Time-step 4: R2 = 0.952701\n",
      "    Time-step 5: R2 = 0.942405\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 758it [00:45, 16.61it/s, train_loss=-0.684590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Train Loss: -0.711945, Train R2: 0.976520\n",
      "\n",
      "Worst 5 Time-Steps Train R2:\n",
      "    Time-step 1: R2 = 0.948087\n",
      "    Time-step 2: R2 = 0.970400\n",
      "    Time-step 3: R2 = 0.974444\n",
      "    Time-step 50: R2 = 0.975829\n",
      "    Time-step 49: R2 = 0.976004\n",
      "Best 5 Time-Steps Train R2:\n",
      "    Time-step 9: R2 = 0.978234\n",
      "    Time-step 14: R2 = 0.978193\n",
      "    Time-step 17: R2 = 0.978150\n",
      "    Time-step 12: R2 = 0.978098\n",
      "    Time-step 8: R2 = 0.978094\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 219it [00:34,  6.38it/s, val_loss=26.970810]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Val Loss: 33.265032, Val R2: 0.637597\n",
      "\n",
      "Worst 5 Time-Steps Val R2:\n",
      "    Time-step 50: R2 = 0.258892\n",
      "    Time-step 49: R2 = 0.274275\n",
      "    Time-step 48: R2 = 0.287786\n",
      "    Time-step 47: R2 = 0.302049\n",
      "    Time-step 46: R2 = 0.317016\n",
      "Best 5 Time-Steps Val R2:\n",
      "    Time-step 1: R2 = 0.981694\n",
      "    Time-step 2: R2 = 0.971604\n",
      "    Time-step 3: R2 = 0.961999\n",
      "    Time-step 4: R2 = 0.952513\n",
      "    Time-step 5: R2 = 0.942870\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = TimeSeriesHuggingFaceTransformer(\n",
    "    input_window_len = input_window_length,\n",
    "    output_window_len = label_window_length,\n",
    "    input_dim = len(input_features),\n",
    "    output_dim = len(label_features),\n",
    "    d_model = embedding_dim,\n",
    "    num_head = num_attention_head,\n",
    "    num_encoder_layers = num_encoder_layers,\n",
    "    num_decoder_layers = num_encoder_layers,\n",
    "    position_wise_ffn_dim = position_wise_nn_dim,\n",
    "    relative_attention_num_buckets = relative_attention_num_buckets,\n",
    "    dropout = dropout\n",
    ").to(device)\n",
    "\n",
    "overfit_monitor = Overfit()\n",
    "\n",
    "print(f\"Number of trainable parameters in the model: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\\n\")\n",
    "\n",
    "criterion = torch.nn.GaussianNLLLoss(full = True)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr = learning_rate\n",
    ")\n",
    "\n",
    "train_r2 = R2Score(multioutput = \"uniform_average\").to(device)\n",
    "val_r2 = R2Score(multioutput = \"uniform_average\").to(device)\n",
    "\n",
    "train_per_timestep_r2 = [R2Score(multioutput = \"uniform_average\").to(device) for _ in range(label_window_length)]\n",
    "val_per_timestep_r2 = [R2Score(multioutput = \"uniform_average\").to(device) for _ in range(label_window_length)]\n",
    "\n",
    "overfit_count = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_r2_value = train(\n",
    "        model = model,\n",
    "        optimizer = optimizer,\n",
    "        criterion = criterion,\n",
    "        r2 = train_r2,\n",
    "        per_timestep_r2 = train_per_timestep_r2,\n",
    "        data_loader = data_loader_train,\n",
    "        device = device,\n",
    "        epoch = epoch,\n",
    "        total_epochs = epochs\n",
    "    )\n",
    "\n",
    "    val_loss, val_r2_value = validate(\n",
    "        model = model,\n",
    "        criterion = criterion,\n",
    "        r2 = val_r2,\n",
    "        per_timestep_r2 = val_per_timestep_r2,\n",
    "        data_loader = data_loader_val,\n",
    "        device = device,\n",
    "        epoch = epoch,\n",
    "        total_epochs = epochs\n",
    "    )\n",
    "\n",
    "    # if(overfit_monitor.check(epoch = epoch, train_loss = train_loss, val_loss = val_loss)):\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02088250",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_path)\n",
    "\n",
    "description = '''\n",
    "dataset: random\n",
    "bos_projector: non-linear (1 LeakyReLU)\n",
    "bos_input: encoder hidden state of last input time-step\n",
    "positional encoding: sin, cos\n",
    "Loss: Gaussian negative log likelihood -> mean and var pred for each time-step\n",
    "seed_val: 7\n",
    "num_single_sample_timesteps: 1000\n",
    "input_window_len: 50\n",
    "label_window_len: 50\n",
    "window_stride: 10\n",
    "relative_attention_num_buckets: 64\n",
    "embedding_dim: 128\n",
    "num_attention_head: 8\n",
    "num_encoder_layers: 5\n",
    "num_decoder_layers: 5\n",
    "position_wise_nn_dim: 64\n",
    "dropout: 0.5\n",
    "batch_size: 128\n",
    "epochs: 5\n",
    "learning_rate: 0.0005\n",
    "psi_e, b_e, psi_plus, b_plus, u_list, eta_list -> psi_e, b_e, psi_plus, b_plus, u_list\n",
    "\n",
    "'''\n",
    "\n",
    "with open(\"./results/experiments.txt\", mode = \"a\") as f:\n",
    "    f.write(str(datetime.now()).replace(\" \", \"-\") + \"\\n\")\n",
    "    f.write(f\"{model_path}\\n\\n\")\n",
    "    f.write(f\"Training Loss: {train_loss}, Training R2: {train_r2_value}\\n\")\n",
    "    f.write(f\"Validation Loss: {val_loss}, Validation R2: {val_r2_value}\\n\")\n",
    "    f.write(description)\n",
    "    f.write(\"==========================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee160512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbe7a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b6bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5730cf0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
